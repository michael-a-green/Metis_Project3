{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "Fraud detection. Using dataset from Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T12:35:07.914474Z",
     "iopub.status.busy": "2020-10-20T12:35:07.914185Z",
     "iopub.status.idle": "2020-10-20T12:35:07.923820Z",
     "shell.execute_reply": "2020-10-20T12:35:07.923058Z",
     "shell.execute_reply.started": "2020-10-20T12:35:07.914444Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, classification_report\n",
    "\n",
    "import pymysql.cursors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T12:35:10.712451Z",
     "iopub.status.busy": "2020-10-20T12:35:10.712166Z",
     "iopub.status.idle": "2020-10-20T12:35:10.715713Z",
     "shell.execute_reply": "2020-10-20T12:35:10.715132Z",
     "shell.execute_reply.started": "2020-10-20T12:35:10.712421Z"
    }
   },
   "outputs": [],
   "source": [
    "#Constants\n",
    "RANDOM_STATE = 999\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "#set this to 1 if you want to see this\n",
    "#notebook create the table and import the CSV into the table\n",
    "#on the My SQL server\n",
    "RUN_TABLE_CREATE_IMPORT = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download and Load Into SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note if you want a copy of the data you can download it from [here](https://www.kaggle.com/ntnu-testimon/paysim1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T12:35:16.512013Z",
     "iopub.status.busy": "2020-10-20T12:35:16.511736Z",
     "iopub.status.idle": "2020-10-20T12:35:16.520308Z",
     "shell.execute_reply": "2020-10-20T12:35:16.519695Z",
     "shell.execute_reply.started": "2020-10-20T12:35:16.511985Z"
    }
   },
   "outputs": [],
   "source": [
    "#just reading enough to get the names of the columns\n",
    "data_df = pd.read_csv(\"../Data/PS_20174392719_1491204439457_log.csv\",nrows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T12:35:17.251267Z",
     "iopub.status.busy": "2020-10-20T12:35:17.251005Z",
     "iopub.status.idle": "2020-10-20T12:35:17.256090Z",
     "shell.execute_reply": "2020-10-20T12:35:17.255523Z",
     "shell.execute_reply.started": "2020-10-20T12:35:17.251238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step\n",
      "type\n",
      "amount\n",
      "nameOrig\n",
      "oldbalanceOrg\n",
      "newbalanceOrig\n",
      "nameDest\n",
      "oldbalanceDest\n",
      "newbalanceDest\n",
      "isFraud\n",
      "isFlaggedFraud\n"
     ]
    }
   ],
   "source": [
    "#Getting column names\n",
    "COL_NAMES = data_df.columns\n",
    "for a_col in COL_NAMES:\n",
    "    print(a_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T12:36:13.401823Z",
     "iopub.status.busy": "2020-10-20T12:36:13.401553Z",
     "iopub.status.idle": "2020-10-20T12:36:13.417590Z",
     "shell.execute_reply": "2020-10-20T12:36:13.417116Z",
     "shell.execute_reply.started": "2020-10-20T12:36:13.401794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What type of data is in each column?\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T12:36:13.868874Z",
     "iopub.status.busy": "2020-10-20T12:36:13.868611Z",
     "iopub.status.idle": "2020-10-20T12:36:13.874298Z",
     "shell.execute_reply": "2020-10-20T12:36:13.873734Z",
     "shell.execute_reply.started": "2020-10-20T12:36:13.868846Z"
    }
   },
   "outputs": [],
   "source": [
    "#Establishing connection to mariaDB server\n",
    "#Note, sever_details.txt is not provided you'll have to ask me for it\n",
    "server_details_file_name = \"/home/magreen/Dropbox/PERSONAL/Documents/Word/server_details.txt\"\n",
    "SERVER_DETAILS = open(server_details_file_name,\"r\")\n",
    "line_of_text = SERVER_DETAILS.readline()\n",
    "\n",
    "host_name, username, mypassword, db_name = line_of_text.split(',')\n",
    "\n",
    "host_name = host_name.rstrip()\n",
    "host_name = host_name.lstrip()\n",
    "username = username.rstrip()\n",
    "username = username.lstrip()\n",
    "mypassword = mypassword.rstrip()\n",
    "mypassword = mypassword.lstrip()\n",
    "db_name = db_name.rstrip()\n",
    "db_name = db_name.lstrip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T12:36:14.799337Z",
     "iopub.status.busy": "2020-10-20T12:36:14.799069Z",
     "iopub.status.idle": "2020-10-20T12:36:14.814807Z",
     "shell.execute_reply": "2020-10-20T12:36:14.813999Z",
     "shell.execute_reply.started": "2020-10-20T12:36:14.799309Z"
    }
   },
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host=host_name, user=username, password=mypassword, db=db_name, cursorclass=pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T12:36:15.409668Z",
     "iopub.status.busy": "2020-10-20T12:36:15.409387Z",
     "iopub.status.idle": "2020-10-20T12:36:15.413214Z",
     "shell.execute_reply": "2020-10-20T12:36:15.412559Z",
     "shell.execute_reply.started": "2020-10-20T12:36:15.409638Z"
    }
   },
   "outputs": [],
   "source": [
    "#get a cursor\n",
    "mycursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T12:36:16.047822Z",
     "iopub.status.busy": "2020-10-20T12:36:16.047552Z",
     "iopub.status.idle": "2020-10-20T12:36:16.053223Z",
     "shell.execute_reply": "2020-10-20T12:36:16.052611Z",
     "shell.execute_reply.started": "2020-10-20T12:36:16.047793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping MySQL table creation and CSV import\n"
     ]
    }
   ],
   "source": [
    "#Create table import entire CSV\n",
    "if RUN_TABLE_CREATE_IMPORT != 0:\n",
    "    drop_table_query = \"drop table if exists paysim_data;\"\n",
    "\n",
    "    mycursor.execute(drop_table_query)\n",
    "    mycursor.execute(\"commit;\")\n",
    "\n",
    "    create_table_query = \"\"\"\n",
    "\n",
    "\n",
    "create table paysim_data (\n",
    "    step INT,\n",
    "    type TEXT,\n",
    "    amount REAL,\n",
    "    nameOrig TEXT,\n",
    "    oldbalanceOrg REAL,\n",
    "    newbalanceOrig REAL,\n",
    "    nameDest TEXT,\n",
    "    oldbalanceDest REAL,\n",
    "    newbalanceDest REAL,\n",
    "    isFraud INT,\n",
    "    isFlaggedFraud INT\n",
    "    );\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    mycursor.execute(create_table_query)\n",
    "    mycursor.execute(\"commit;\")\n",
    "\n",
    "    import_query = \"\"\"\n",
    "\n",
    "\n",
    "load data infile '/var/lib/mysql-files/data/PS_20174392719_1491204439457_log.csv'\n",
    "into table paysim_data fields terminated by ','  lines terminated by '\\n'\n",
    "ignore 1 rows;\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mycursor.execute(import_query)\n",
    "    mycursor.execute(\"commit;\")\n",
    "    print(\"table creation and import done\")\n",
    "else:\n",
    "    print(\"Skipping MySQL table creation and CSV import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-20T12:36:20.230331Z",
     "iopub.status.busy": "2020-10-20T12:36:20.230065Z"
    }
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#\n",
    "# Search each column in the MySQL table for null. If null remove the row\n",
    "#\n",
    "########################################################################\n",
    "for column_name in COL_NAMES:\n",
    "    temp_query = \"\"\"\n",
    "    \n",
    "    select * from paysim_data where {} is null;\n",
    "    \n",
    "    \"\"\".format(column_name)\n",
    "    \n",
    "    mycursor.execute(\"begin;\")\n",
    "    query_result = mycursor.execute(temp_query)\n",
    "    print(\"For column = {} here are the null rows:\\n\".format(column_name))\n",
    "    print(query_result)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if query_result != 0:\n",
    "        row_contents = mycursor.fetchall()\n",
    "        print(\"This row contains NULL information:\\n\")\n",
    "        \n",
    "        for bad_row in row_contents:\n",
    "            print(row_contents)\n",
    "            \n",
    "        temp_efface_row_query = \"\"\"\n",
    "        delete from paysim_data where {} is null;\n",
    "        \"\"\".format(column_name)\n",
    "        \n",
    "        query_result = mycursor.execute(temp_efface_row_query)\n",
    "        \n",
    "        #print(\"result = {}\".format(query_result))\n",
    "        mycursor.execute(\"commit;\")\n",
    "        #print(\"result = {}\".format(query_result))\n",
    "        if query_result:\n",
    "            print(\"\\nsuccessfully removed row\\n\")\n",
    "        else:\n",
    "            print(\"error: failed to remove row!\")\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "print(\"\\ncheck done.\\n\")\n",
    "#Create table\n",
    "\n",
    "#import CSV Into SQL Table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"isFraud\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial thought is that `isFraud` is basically a function of `type` and `amount`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot-encoding `type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "np_data_type = np.array(data_df[\"type\"])\n",
    "np_data_type = np_data_type.reshape(-1,1)\n",
    "np_data_type.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data_type_ohe = ohe.fit_transform(np_data_type)\n",
    "np_data_type_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data_type_ohe_df= pd.DataFrame(np_data_type_ohe,\n",
    "                           columns=ohe.get_feature_names(['type']), #create meaningful column names\n",
    "                           index=data_df.index) #keep the same index values\n",
    "\n",
    "#np_data_type_ohe_df.head()\n",
    "\n",
    "#combine continuous and categorical data\n",
    "\n",
    "data_df = pd.concat([data_df, np_data_type_ohe_df], axis=1)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plot to help me understand how mixed together `isFraud==0` is with `isFraud==1` as a function of `type` and `amount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_RANDOM_SAMPLES = 6000\n",
    "\n",
    "plot_data_df = data_df[[\"step\",\"isFraud\",\"amount\",\"type_CASH_IN\",\"type_CASH_OUT\",\"type_DEBIT\",\"type_PAYMENT\",\"type_TRANSFER\"]]\n",
    "#limit to the first time step\n",
    "plot_data_df = plot_data_df[ plot_data_df[\"step\"] == 1 ]\n",
    "#np_plot_data_df_indices = list(np.random.permutation(np.array(list(plot_data_df.index)))[:5000])\n",
    "#sns.pairplot(plot_data_df.iloc[[np_plot_data_df_indices]], hue='isFraud');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is generating the index numbers for data frame plot_data_df\n",
    "#then randomizing the list containing those indices\n",
    "#then picking the first NUM_OF_RANDOM_SAMPLES from that list\n",
    "#this list of randomly picked indices will be used to pick the corresponding\n",
    "#rows out of plot_data_df to be used in the pair plot\n",
    "#to plot all 6M rows is not practical (on this machine) \n",
    "plot_data_df_indices = list(plot_data_df.index)\n",
    "plot_data_df_indices = np.random.permutation(plot_data_df_indices)\n",
    "plot_data_df_indices = plot_data_df_indices[:NUM_OF_RANDOM_SAMPLES]\n",
    "plot_data_df_indices = list(plot_data_df_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " plot_data_df = plot_data_df.iloc[plot_data_df_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(plot_data_df, hue='isFraud');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not looking like good parameters :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Guessing (50% chance of `isFraud==1` and 50% chance that `isFraud==0` will be the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df[[\"step\",\"amount\",\"type_CASH_IN\",\"type_CASH_OUT\",\"type_DEBIT\",\"type_PAYMENT\",\"type_TRANSFER\"]]\n",
    "Y = data_df[\"isFraud\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "number_of_test_samples = X_test.shape[0]\n",
    "y_pred_zero = np.zeros(number_of_test_samples // 2)\n",
    "y_pred_one = np.ones( number_of_test_samples -  y_pred_zero.shape[0] )\n",
    "\n",
    "y_pred = np.array([y_pred_zero, y_pred_one])\n",
    "y_pred = y_pred.reshape(-1,)\n",
    "y_pred = np.random.permutation(y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"NotFraud\",\"Fraud\"]\n",
    "print(classification_report(Y_test, y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts about random guessing model:\n",
    "\n",
    "Precision (TP/(TP+FP)) and recall (TP/(TP+FN)) are high for the `NotFraud` class because most (99.97%) of the response variables in the test set are `NotFraud`. Precision and recall are very low for `Fraud` because there are very few chances to guess right and the random guessing model does not perform well in identifying them.\n",
    "\n",
    "Accuracy is meaningless for the same reason: It's easy to get 50% right as the vast majority of the results belong to one class. \n",
    "\n",
    "TODO: generate confusion matrix which will help illustrate this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just some notes about what model to select:\n",
    "\n",
    "**Logistic Models**\n",
    "For small datasets, ‘liblinear’ is a good choice, whereas ‘sag’ and ‘saga’ are faster for large ones.\n",
    "\n",
    "Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since I'm using values that are either 1 or 0 along with amount which is a very large number, will normalize the data\n",
    "#to aid gradient descent\n",
    "normalizer = StandardScaler()\n",
    "X_train_normal = normalizer.fit_transform(X_train.values)\n",
    "X_test_normal = normalizer.transform(X_test.values)\n",
    "\n",
    "#logisticRModel = LogisticRegressionCV(Cs=100,cv=5,solver=\"sag\",n_jobs=-1,random_state=RANDOM_STATE)\n",
    "logisticRModel = LogisticRegression(C=100,solver=\"sag\",n_jobs=-1,random_state=RANDOM_STATE)\n",
    "\n",
    "logisticRModel.fit(X_train_normal,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = logisticRModel.predict(X_test_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, Y_pred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRModel.score(X_test_normal,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_df = pd.DataFrame(Y_pred)\n",
    "Y_pred_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRModel.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts about baseline logistic model:\n",
    "\n",
    "Precision (TP/(TP+FP)) and recall (TP/(TP+FN)) are high for the `NotFraud` because most(99.97%) of the response variables in the test set are `NotFraud`. Precision and recall are very low for `Fraud` because there are very few chances to guess right and the random guessing model does not perform well in identify them.\n",
    "\n",
    "Accuracy is meaningless for the same reason: It's easy to get 50% right as the vast majority of the results belong to one class. \n",
    "\n",
    "TODO: generate confusion matrix which will help illustrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
