{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will develop a machine learning model to perform fraudulent transaction detection for transactions performed on a mobile payment system. The transaction data is generated by a simulator that generates 31 days of transactions that are statistically similar to real transactions performed on a real mobile payment system for the same period of time. If you would like to know more about the data set you can go [here](https://www.kaggle.com/ntnu-testimon/paysim1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T23:00:52.905570Z",
     "iopub.status.busy": "2020-10-24T23:00:52.905262Z",
     "iopub.status.idle": "2020-10-24T23:00:54.818393Z",
     "shell.execute_reply": "2020-10-24T23:00:54.817826Z",
     "shell.execute_reply.started": "2020-10-24T23:00:52.905487Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, classification_report, confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "import pymysql.cursors\n",
    "import sys\n",
    "\n",
    "#to speed up pandas operands\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "#GPU\n",
    "\n",
    "import cupy as cnp\n",
    "import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from cuml import train_test_split as gputrain_test_split\n",
    "from cuml import LinearRegression as gpuLinearRegression\n",
    "from cuml import KMeans as gpuKmeans\n",
    "from cuml import LogisticRegression as gpuLogisticRegression\n",
    "from cuml.ensemble import RandomForestClassifier as gpuRandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T23:21:00.318282Z",
     "iopub.status.busy": "2020-10-24T23:21:00.318023Z",
     "iopub.status.idle": "2020-10-24T23:21:00.322082Z",
     "shell.execute_reply": "2020-10-24T23:21:00.321268Z",
     "shell.execute_reply.started": "2020-10-24T23:21:00.318253Z"
    }
   },
   "outputs": [],
   "source": [
    "#These are top-level variables used to control the operation of the notebook\n",
    "\n",
    "#random seed used to initialize machine learning models and data set maniuplation functions\n",
    "RANDOM_STATE = 999\n",
    "\n",
    "#used to determine what percent of the overall data set will be used for testing trained models\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "# When this is a 1, this notebook will access clean the data on the SQL server and download the data to this notebook\n",
    "# please note this will require credentials and it takes time\n",
    "#\n",
    "# In lieu of that I can make available a pickle file of the post-cleaned SQL table in which case\n",
    "# you can ask me for it and you won't need to set this variable to 1.\n",
    "#\n",
    "RUN_TABLE_CREATE_IMPORT = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import Data Cleaning In SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is uploaded to a remote SQL server. The credentials to that server is accessesd by this notebook in a file held securely. If you would like access to this server please let me know and I'll send it to you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am reading in the first few lines of the data set to get the names of the columns and the types of data within each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T23:27:24.282448Z",
     "iopub.status.busy": "2020-10-24T23:27:24.282194Z",
     "iopub.status.idle": "2020-10-24T23:27:24.302593Z",
     "shell.execute_reply": "2020-10-24T23:27:24.301914Z",
     "shell.execute_reply.started": "2020-10-24T23:27:24.282421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>C1231006815</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>M1979787155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>C1666544295</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>M2044282225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C840083671</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C38997010</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>C2048537720</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>M1230701703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
       "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
       "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
       "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
       "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
       "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
       "\n",
       "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0  M1979787155             0.0             0.0        0               0  \n",
       "1  M2044282225             0.0             0.0        0               0  \n",
       "2   C553264065             0.0             0.0        1               0  \n",
       "3    C38997010         21182.0             0.0        1               0  \n",
       "4  M1230701703             0.0             0.0        0               0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"../Data/PS_20174392719_1491204439457_log.csv\",nrows=5)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T23:27:25.054120Z",
     "iopub.status.busy": "2020-10-24T23:27:25.053779Z",
     "iopub.status.idle": "2020-10-24T23:27:25.060714Z",
     "shell.execute_reply": "2020-10-24T23:27:25.059914Z",
     "shell.execute_reply.started": "2020-10-24T23:27:25.054083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step\n",
      "amount\n",
      "nameOrig\n",
      "oldbalanceOrg\n",
      "newbalanceOrig\n",
      "nameDest\n",
      "oldbalanceDest\n",
      "newbalanceDest\n",
      "isFraud\n",
      "isFlaggedFraud\n",
      "transtype\n"
     ]
    }
   ],
   "source": [
    "#COL_NAMES will be used to clean the database on the SQL server\n",
    "COL_NAMES = data_df.columns\n",
    "COL_NAMES = list(COL_NAMES)\n",
    "COL_NAMES.remove(\"type\")\n",
    "COL_NAMES.append(\"transtype\")\n",
    "for i, a_col in enumerate(COL_NAMES):\n",
    "    print(a_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this information will be used to create the SQL table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining credentials to log into the SQL server. Note this was developed to work on a mac or a Linux machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T23:21:05.027263Z",
     "iopub.status.busy": "2020-10-24T23:21:05.026998Z",
     "iopub.status.idle": "2020-10-24T23:21:05.033632Z",
     "shell.execute_reply": "2020-10-24T23:21:05.032939Z",
     "shell.execute_reply.started": "2020-10-24T23:21:05.027232Z"
    }
   },
   "outputs": [],
   "source": [
    "#Establishing connection to mariaDB server\n",
    "#Note, sever_details.txt is not provided you'll have to ask me for it\n",
    "if sys.platform == 'linux':\n",
    "    server_details_file_name = \"/home/magreen/Dropbox/PERSONAL/Documents/Word/server_details.txt\"\n",
    "elif sys.platform == 'darwin':\n",
    "    server_details_file_name = \"/Users/magreen/Dropbox/PERSONAL/Documents/Word/server_details.txt\"\n",
    "else:\n",
    "    print(\"WARNING: You are running on a system type I have not tested. Please contact me if you want help testing this.\")\n",
    "\n",
    "SERVER_DETAILS = open(server_details_file_name,\"r\")\n",
    "line_of_text = SERVER_DETAILS.readline()\n",
    "\n",
    "host_name, username, mypassword, db_name = line_of_text.split(',')\n",
    "\n",
    "host_name = host_name.rstrip()\n",
    "host_name = host_name.lstrip()\n",
    "username = username.rstrip()\n",
    "username = username.lstrip()\n",
    "mypassword = mypassword.rstrip()\n",
    "mypassword = mypassword.lstrip()\n",
    "db_name = db_name.rstrip()\n",
    "db_name = db_name.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T23:21:06.074634Z",
     "iopub.status.busy": "2020-10-24T23:21:06.074383Z",
     "iopub.status.idle": "2020-10-24T23:21:06.077347Z",
     "shell.execute_reply": "2020-10-24T23:21:06.076715Z",
     "shell.execute_reply.started": "2020-10-24T23:21:06.074606Z"
    }
   },
   "outputs": [],
   "source": [
    "#This data frame is no longer needed so deleting it\n",
    "del data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a connection to the SQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T23:21:13.339429Z",
     "iopub.status.busy": "2020-10-24T23:21:13.339180Z",
     "iopub.status.idle": "2020-10-24T23:21:13.354394Z",
     "shell.execute_reply": "2020-10-24T23:21:13.353654Z",
     "shell.execute_reply.started": "2020-10-24T23:21:13.339402Z"
    }
   },
   "outputs": [],
   "source": [
    "connection = pymysql.connect(host=host_name, user=username, password=mypassword, db=db_name, cursorclass=pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this code will create the table on the SQL server, upload a copy of the original [data set CSV file](https://www.kaggle.com/ntnu-testimon/paysim1), remove rows that may contain null data, and find and remove duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T23:21:14.617515Z",
     "iopub.status.busy": "2020-10-24T23:21:14.617260Z",
     "iopub.status.idle": "2020-10-24T23:21:14.620555Z",
     "shell.execute_reply": "2020-10-24T23:21:14.619838Z",
     "shell.execute_reply.started": "2020-10-24T23:21:14.617487Z"
    }
   },
   "outputs": [],
   "source": [
    "#get a cursor\n",
    "mycursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T23:22:07.331406Z",
     "iopub.status.busy": "2020-10-24T23:22:07.331151Z",
     "iopub.status.idle": "2020-10-24T23:25:13.731756Z",
     "shell.execute_reply": "2020-10-24T23:25:13.731011Z",
     "shell.execute_reply.started": "2020-10-24T23:22:07.331378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table creation and import done\n"
     ]
    }
   ],
   "source": [
    "#Create table import entire CSV\n",
    "if RUN_TABLE_CREATE_IMPORT != 0:\n",
    "    drop_table_query = \"drop table if exists paysim_data2;\"\n",
    "\n",
    "    mycursor.execute(drop_table_query)\n",
    "    mycursor.execute(\"commit;\")\n",
    "\n",
    "    create_table_query = \"\"\"\n",
    "\n",
    "\n",
    "create table paysim_data2 (\n",
    "    step INT,\n",
    "    transtype VARCHAR(255),\n",
    "    amount REAL,\n",
    "    nameOrig VARCHAR(255),\n",
    "    oldbalanceOrg REAL,\n",
    "    newbalanceOrig REAL,\n",
    "    nameDest VARCHAR(255),\n",
    "    oldbalanceDest REAL,\n",
    "    newbalanceDest REAL,\n",
    "    isFraud INT,\n",
    "    isFlaggedFraud INT\n",
    "    );\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    mycursor.execute(create_table_query)\n",
    "    mycursor.execute(\"commit;\")\n",
    "\n",
    "    import_query = \"\"\"\n",
    "\n",
    "\n",
    "load data infile '/var/lib/mysql-files/data/PS_20174392719_1491204439457_log.csv'\n",
    "into table paysim_data2 fields terminated by ','  lines terminated by '\\n'\n",
    "ignore 1 rows;\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mycursor.execute(import_query)\n",
    "    mycursor.execute(\"commit;\")\n",
    "    \n",
    "    #and a row ID to the table\n",
    "    alter_table_query = \"\"\"\n",
    "    alter table paysim_data2 add column id int auto_increment primary key first;\n",
    "    \"\"\"\n",
    "    mycursor.execute(alter_table_query)\n",
    "    mycursor.execute(\"commit;\")\n",
    "    print(\"table creation and import done\")\n",
    "else:\n",
    "    print(\"Skipping MySQL table creation and CSV import\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T23:19:21.300128Z",
     "iopub.status.busy": "2020-10-24T23:19:21.299864Z",
     "iopub.status.idle": "2020-10-24T23:19:21.304474Z",
     "shell.execute_reply": "2020-10-24T23:19:21.303661Z",
     "shell.execute_reply.started": "2020-10-24T23:19:21.300100Z"
    }
   },
   "source": [
    "In this section I remove rows that contain null entries or duplicate entries from the SQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T23:27:41.351304Z",
     "iopub.status.busy": "2020-10-24T23:27:41.351027Z",
     "iopub.status.idle": "2020-10-24T23:28:25.857022Z",
     "shell.execute_reply": "2020-10-24T23:28:25.856224Z",
     "shell.execute_reply.started": "2020-10-24T23:27:41.351274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For column = step here are the null rows:\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "For column = amount here are the null rows:\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "This row contains NULL information:\n",
      "\n",
      "[{'id': 6362623, 'step': 1, 'transtype': 'PAYMENT', 'amount': None, 'nameOrig': 'C3PO', 'oldbalanceOrg': 100.0, 'newbalanceOrig': 45.0, 'nameDest': 'R2D2', 'oldbalanceDest': 0.0, 'newbalanceDest': 55.0, 'isFraud': 0, 'isFlaggedFraud': 0}]\n",
      "\n",
      "successfully removed row\n",
      "\n",
      "For column = nameOrig here are the null rows:\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "For column = oldbalanceOrg here are the null rows:\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "For column = newbalanceOrig here are the null rows:\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "For column = nameDest here are the null rows:\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "For column = oldbalanceDest here are the null rows:\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "For column = newbalanceDest here are the null rows:\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      "This row contains NULL information:\n",
      "\n",
      "[{'id': 6362624, 'step': 1, 'transtype': 'PAYMENT', 'amount': 10.0, 'nameOrig': 'Luke', 'oldbalanceOrg': 100.0, 'newbalanceOrig': 90.0, 'nameDest': 'Wedge', 'oldbalanceDest': 0.0, 'newbalanceDest': None, 'isFraud': 0, 'isFlaggedFraud': 0}]\n",
      "\n",
      "successfully removed row\n",
      "\n",
      "For column = isFraud here are the null rows:\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "For column = isFlaggedFraud here are the null rows:\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "For column = transtype here are the null rows:\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "check done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "#\n",
    "# Search each column in the MySQL table for null. If null remove the row\n",
    "#\n",
    "########################################################################\n",
    "if RUN_TABLE_CREATE_IMPORT != 0:\n",
    "\n",
    "    for column_name in COL_NAMES:\n",
    "        temp_query = \"\"\"\n",
    "    \n",
    "        select * from paysim_data2 where {} is null;\n",
    "    \n",
    "        \"\"\".format(column_name)\n",
    "    \n",
    "        mycursor.execute(\"begin;\")\n",
    "        query_result = mycursor.execute(temp_query)\n",
    "        print(\"For column = {} here are the null rows:\\n\".format(column_name))\n",
    "        print(query_result)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "        if query_result != 0:\n",
    "            row_contents = mycursor.fetchall()\n",
    "            print(\"This row contains NULL information:\\n\")\n",
    "        \n",
    "            for bad_row in row_contents:\n",
    "                print(row_contents)\n",
    "            \n",
    "            temp_efface_row_query = \"\"\"\n",
    "            delete from paysim_data2 where {} is null;\n",
    "            \"\"\".format(column_name)\n",
    "        \n",
    "            query_result = mycursor.execute(temp_efface_row_query)\n",
    "        \n",
    "            #print(\"result = {}\".format(query_result))\n",
    "            mycursor.execute(\"commit;\")\n",
    "            #print(\"result = {}\".format(query_result))\n",
    "            if query_result:\n",
    "                print(\"\\nsuccessfully removed row\\n\")\n",
    "            else:\n",
    "                print(\"error: failed to remove row!\")\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "    print(\"\\ncheck done.\\n\")\n",
    "else:\n",
    "    print(\"\\nskipping null search and clean\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T23:28:36.416167Z",
     "iopub.status.busy": "2020-10-24T23:28:36.415911Z",
     "iopub.status.idle": "2020-10-24T23:31:50.745645Z",
     "shell.execute_reply": "2020-10-24T23:31:50.744903Z",
     "shell.execute_reply.started": "2020-10-24T23:28:36.416139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "following are duplicate rows in the SQL DB:\n",
      "\n",
      "{'step': 1, 'count(step)': 2, 'transtype': 'PAYMENT', 'count(transtype)': 2, 'amount': 55.0, 'count(amount)': 2, 'nameOrig': 'Han Solo', 'count(nameOrig)': 2, 'oldbalanceOrg': 100.0, 'count(oldbalanceOrg)': 2, 'newbalanceOrig': 45.0, 'count(newbalanceOrig)': 2, 'nameDest': 'Princess Lea', 'count(nameDest)': 2, 'oldbalanceDest': 0.0, 'count(oldbalanceDest)': 2, 'newbalanceDest': 55.0, 'count(newbalanceDest)': 2, 'isFraud': 0, 'count(isFraud)': 2, 'isFlaggedFraud': 0, 'count(isFlaggedFraud)': 2}\n",
      "\n",
      "done searching for duplicates\n",
      "\n",
      "removing duplicates\n",
      "\n",
      "\n",
      "done removing duplicates\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "#\n",
    "# Search for duplicate rows. Remove the second-most row for every pair of duplicate rows\n",
    "#\n",
    "########################################################################\n",
    "\n",
    "search_for_duplicates_query = \"\"\"\n",
    "select\n",
    "     step, count(step),\n",
    "     transtype, count(transtype),\n",
    "     amount, count(amount),\n",
    "     nameOrig, count(nameOrig),\n",
    "     oldbalanceOrg, count(oldbalanceOrg),\n",
    "     newbalanceOrig, count(newbalanceOrig),\n",
    "     nameDest, count(nameDest),\n",
    "     oldbalanceDest, count(oldbalanceDest),\n",
    "     newbalanceDest, count(newbalanceDest),\n",
    "     isFraud, count(isFraud),\n",
    "     isFlaggedFraud, count(isFlaggedFraud)\n",
    "     from paysim_data2\n",
    "     group by step,transtype,amount,nameOrig,oldbalanceOrg,newbalanceOrig,nameDest,oldbalanceDest,newbalanceDest,isFraud,isFlaggedFraud\n",
    "     having\n",
    "     count(step) > 1 and\n",
    "     count(transtype) > 1 and\n",
    "     count(amount) > 1 and\n",
    "     count(nameOrig) > 1 and\n",
    "     count(oldbalanceOrg) > 1 and\n",
    "     count(newbalanceOrig) > 1 and\n",
    "     count(nameDest) > 1 and\n",
    "     count(oldbalanceDest) > 1 and\n",
    "     count(newbalanceDest) > 1 and\n",
    "     count(isFraud) > 1 and\n",
    "     count(isFlaggedFraud) > 1;\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "remove_duplicates_query1 = \"\"\"\n",
    "\n",
    "\n",
    "SET SESSION old_alter_table=1;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "remove_duplicates_query2 = \"\"\"\n",
    "\n",
    "alter ignore table paysim_data2 add unique index u(amount,nameOrig,nameDest);\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "remove_duplicates_query3 = \"\"\"\n",
    "SET SESSION old_alter_table=0;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "if RUN_TABLE_CREATE_IMPORT != 0:\n",
    "\n",
    "    # removing duplicates takes too long will just search for duplicates\n",
    "    # The dataset has 6M rows every duplicate remove I found \n",
    "    # does a n^2 operation which is too many for this DB\n",
    "    # other methods (CTE) don't work\n",
    "    mycursor.execute(\"begin;\")\n",
    "    mycursor.execute(search_for_duplicates_query)\n",
    "    results = mycursor.fetchall()\n",
    "\n",
    "    print(\"following are duplicate rows in the SQL DB:\\n\")\n",
    "    for myresult in results:\n",
    "        print(myresult)\n",
    "    print(\"\\ndone searching for duplicates\\n\")\n",
    "\n",
    "    print(\"removing duplicates\\n\")\n",
    "    mycursor.execute(\"begin;\")\n",
    "    mycursor.execute(remove_duplicates_query1)\n",
    "    mycursor.execute(\"commit;\")\n",
    "    mycursor.execute(remove_duplicates_query2)\n",
    "    mycursor.execute(\"commit;\")\n",
    "    mycursor.execute(remove_duplicates_query3)\n",
    "    mycursor.execute(\"commit;\")\n",
    "    print(\"\\ndone removing duplicates\\n\")\n",
    "else:\n",
    "    print(\"\\nskipping redundant row search and remove\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T22:52:15.559673Z",
     "iopub.status.busy": "2020-10-24T22:52:15.559334Z",
     "iopub.status.idle": "2020-10-24T22:52:15.563791Z",
     "shell.execute_reply": "2020-10-24T22:52:15.562879Z",
     "shell.execute_reply.started": "2020-10-24T22:52:15.559593Z"
    }
   },
   "source": [
    "## Base Line Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T22:53:28.463855Z",
     "iopub.status.busy": "2020-10-24T22:53:28.463600Z",
     "iopub.status.idle": "2020-10-24T22:53:28.466598Z",
     "shell.execute_reply": "2020-10-24T22:53:28.465987Z",
     "shell.execute_reply.started": "2020-10-24T22:53:28.463827Z"
    }
   },
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T22:53:35.415841Z",
     "iopub.status.busy": "2020-10-24T22:53:35.415588Z",
     "iopub.status.idle": "2020-10-24T22:53:35.418735Z",
     "shell.execute_reply": "2020-10-24T22:53:35.417994Z",
     "shell.execute_reply.started": "2020-10-24T22:53:35.415813Z"
    }
   },
   "source": [
    "### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T22:53:46.758787Z",
     "iopub.status.busy": "2020-10-24T22:53:46.758535Z",
     "iopub.status.idle": "2020-10-24T22:53:46.761611Z",
     "shell.execute_reply": "2020-10-24T22:53:46.760908Z",
     "shell.execute_reply.started": "2020-10-24T22:53:46.758759Z"
    }
   },
   "source": [
    "## XGBoost Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T22:54:00.879547Z",
     "iopub.status.busy": "2020-10-24T22:54:00.879280Z",
     "iopub.status.idle": "2020-10-24T22:54:00.882360Z",
     "shell.execute_reply": "2020-10-24T22:54:00.881672Z",
     "shell.execute_reply.started": "2020-10-24T22:54:00.879519Z"
    }
   },
   "source": [
    "### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T22:54:20.805955Z",
     "iopub.status.busy": "2020-10-24T22:54:20.805698Z",
     "iopub.status.idle": "2020-10-24T22:54:20.808752Z",
     "shell.execute_reply": "2020-10-24T22:54:20.808075Z",
     "shell.execute_reply.started": "2020-10-24T22:54:20.805927Z"
    }
   },
   "source": [
    "# Final Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T22:54:52.439875Z",
     "iopub.status.busy": "2020-10-24T22:54:52.439495Z",
     "iopub.status.idle": "2020-10-24T22:54:52.443619Z",
     "shell.execute_reply": "2020-10-24T22:54:52.442607Z",
     "shell.execute_reply.started": "2020-10-24T22:54:52.439832Z"
    }
   },
   "source": [
    "## Precision / Recall Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-24T22:54:57.546300Z",
     "iopub.status.busy": "2020-10-24T22:54:57.546045Z",
     "iopub.status.idle": "2020-10-24T22:54:57.549158Z",
     "shell.execute_reply": "2020-10-24T22:54:57.548445Z",
     "shell.execute_reply.started": "2020-10-24T22:54:57.546270Z"
    }
   },
   "source": [
    "## ROC Curves and AUC Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
